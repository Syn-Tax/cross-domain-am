@misc{baevskiWav2vec20Framework2020,
  title = {Wav2vec 2.0: {{A Framework}} for {{Self-Supervised Learning}} of {{Speech Representations}}},
  shorttitle = {Wav2vec 2.0},
  author = {Baevski, Alexei and Zhou, Henry and Mohamed, Abdelrahman and Auli, Michael},
  year = {2020},
  month = oct,
  number = {arXiv:2006.11477},
  eprint = {2006.11477},
  publisher = {arXiv},
  urldate = {2024-10-16},
  abstract = {We show for the first time that learning powerful representations from speech audio alone followed by fine-tuning on transcribed speech can outperform the best semi-supervised methods while being conceptually simpler. wav2vec 2.0 masks the speech input in the latent space and solves a contrastive task defined over a quantization of the latent representations which are jointly learned. Experiments using all labeled data of Librispeech achieve 1.8/3.3 WER on the clean/other test sets. When lowering the amount of labeled data to one hour, wav2vec 2.0 outperforms the previous state of the art on the 100 hour subset while using 100 times less labeled data. Using just ten minutes of labeled data and pre-training on 53k hours of unlabeled data still achieves 4.8/8.2 WER. This demonstrates the feasibility of speech recognition with limited amounts of labeled data.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {C\:\\Users\\twoca\\Zotero\\storage\\Q26TQS78\\Baevski et al. - 2020 - wav2vec 2.0 A Framework for Self-Supervised Learning of Speech Representations.pdf;C\:\\Users\\twoca\\Zotero\\storage\\7C72PL3J\\2006.html}
}

@incollection{budzynskaArgumentMiningDialogue2014,
  title = {Towards {{Argument Mining}} from {{Dialogue}}},
  booktitle = {Computational {{Models}} of {{Argument}}},
  author = {Budzynska, Katarzyna and Janier, Mathilde and Kang, Juyeon and Reed, Chris and {Saint-Dizier}, Patrick and Stede, Manfred and Yaskorska, Olena},
  year = {2014},
  pages = {185--196},
  publisher = {IOS Press},
  doi = {10.3233/978-1-61499-436-7-185},
  urldate = {2025-01-27}
}

@inproceedings{budzynskaModelProcessingIllocutionary2014,
  title = {A {{Model}} for {{Processing Illocutionary Structures}} and {{Argumentation}} in {{Debates}}},
  booktitle = {Proceedings of the {{Ninth International Conference}} on {{Language Resources}} and {{Evaluation}} ({{LREC}}`14)},
  author = {Budzynska, Kasia and Janier, Mathilde and Reed, Chris and {Saint-Dizier}, Patrick and Stede, Manfred and Yakorska, Olena},
  editor = {Calzolari, Nicoletta and Choukri, Khalid and Declerck, Thierry and Loftsson, Hrafn and Maegaard, Bente and Mariani, Joseph and Moreno, Asuncion and Odijk, Jan and Piperidis, Stelios},
  year = {2014},
  month = may,
  pages = {917--924},
  publisher = {European Language Resources Association (ELRA)},
  address = {Reykjavik, Iceland},
  urldate = {2025-01-27},
  abstract = {In this paper, we briefly present the objectives of Inference Anchoring Theory (IAT) and the formal structure which is proposed for dialogues. Then, we introduce our development corpus, and a computational model designed for the identification of discourse minimal units in the context of argumentation and the illocutionary force associated with each unit. We show the categories of resources which are needed and how they can be reused in different contexts.},
  file = {C:\Users\twoca\Zotero\storage\KJ9NZAB7\Budzynska et al. - 2014 - A Model for Processing Illocutionary Structures and Argumentation in Debates.pdf}
}

@article{chesnevarArgumentInterchangeFormat2006,
  title = {Towards an Argument Interchange Format},
  author = {Ches{\~n}evar, Carlos and {Mcginnis} and Modgil, Sanjay and Rahwan, Iyad and Reed, Chris and Simari, Guillermo and South, Matthew and Vreeswijk, Gerard and Willmott, Steven},
  year = {2006},
  month = dec,
  journal = {The Knowledge Engineering Review},
  volume = {21},
  number = {4},
  pages = {293--316},
  issn = {0269-8889, 1469-8005},
  doi = {10.1017/S0269888906001044},
  urldate = {2025-01-28},
  abstract = {The theory of argumentation is a rich, interdisciplinary area of research straddling the fields of artificial intelligence, philosophy, communication studies, linguistics, and psychology. In the last years, significant progress has been made in understanding the theoretical properties of different argumentation logics. However, one major barrier to the development and practical deployment of argumentation systems is the lack of a shared, agreed notation or ``interchange format'' for argumentation and arguments. This article describes a draft specification for an Argument Interchange Format (AIF) intended for representation and exchange of data between various argumentation tools and agent-based applications. It represents a consensus `abstract model' established by researchers across fields of argumentation, artificial intelligence and multi-agent systems.1 In its current form, this specification is intended as a starting point for further discussion and elaboration by the community, rather than an attempt at a definitive, all encompassing model. However, to demonstrate proof of concept, a use case scenario is briefly described. Moreover, three concrete realisations or `reifications' of the abstract model are illustrated.},
  copyright = {https://www.cambridge.org/core/terms},
  langid = {english},
  file = {C:\Users\twoca\Zotero\storage\CJGBMPVI\Ches√±evar et al. - 2006 - Towards an argument interchange format.pdf}
}

@misc{devlinBERTPretrainingDeep2019b,
  title = {{{BERT}}: {{Pre-training}} of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  shorttitle = {{{BERT}}},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  year = {2019},
  month = may,
  number = {arXiv:1810.04805},
  eprint = {1810.04805},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1810.04805},
  urldate = {2025-01-13},
  abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\twoca\\Zotero\\storage\\AN5I3PLY\\Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf;C\:\\Users\\twoca\\Zotero\\storage\\M9JU6UCV\\1810.html}
}

@inproceedings{duthieCASSTechniqueEvaluating2016,
  title = {The {{CASS Technique}} for {{Evaluating}} the {{Performance}} of {{Argument Mining}}},
  booktitle = {Proceedings of the {{Third Workshop}} on {{Argument Mining}} ({{ArgMining2016}})},
  author = {Duthie, Rory and Lawrence, John and Budzynska, Katarzyna and Reed, Chris},
  editor = {Reed, Chris},
  year = {2016},
  month = aug,
  pages = {40--49},
  publisher = {Association for Computational Linguistics},
  address = {Berlin, Germany},
  doi = {10.18653/v1/W16-2805},
  urldate = {2024-10-24},
  file = {C:\Users\twoca\Zotero\storage\75JZYJCI\Duthie et al. - 2016 - The CASS Technique for Evaluating the Performance of Argument Mining.pdf}
}

@inproceedings{gemechuARIESGeneralBenchmark2024,
  title = {{{ARIES}}: {{A General Benchmark}} for {{Argument Relation Identification}}},
  shorttitle = {{{ARIES}}},
  booktitle = {Proceedings of the 11th {{Workshop}} on {{Argument Mining}} ({{ArgMining}} 2024)},
  author = {Gemechu, Debela and {Ruiz-Dolz}, Ramon and Reed, Chris},
  editor = {Ajjour, Yamen and {Bar-Haim}, Roy and El Baff, Roxanne and Liu, Zhexiong and Skitalinskaya, Gabriella},
  year = {2024},
  month = aug,
  pages = {1--14},
  publisher = {Association for Computational Linguistics},
  address = {Bangkok, Thailand},
  doi = {10.18653/v1/2024.argmining-1.1},
  urldate = {2024-10-14},
  abstract = {Measuring advances in argument mining is one of the main challenges in the area. Different theories of argument, heterogeneous annotations, and a varied set of argumentation domains make it difficult to contextualise and understand the results reported in different work from a general perspective. In this paper, we present ARIES, a general benchmark for Argument Relation Identification aimed at providing with a standard evaluation for argument mining research. ARIES covers the three different language modelling approaches: sequence and token modelling, and sequence-to-sequence-to-sequence alignment, together with the three main Transformer-based model architectures: encoder-only, decoder-only, and encoder-decoder. Furthermore, the benchmark consists of eight different argument mining datasets, covering the most common argumentation domains, and standardised with the same annotation structures. This paper provides a first comprehensive and comparative set of results in argument mining across a broad range of configurations to compare with, both advancing the state-of-the-art, and establishing a standard way to measure future advances in the area. Across varied task setups and architectures, our experiments reveal consistent challenges in cross-dataset evaluation, with notably poor results. Given the models' struggle to acquire transferable skills, the task remains challenging, opening avenues for future research.},
  file = {C:\Users\twoca\Zotero\storage\XVMPNCHL\Gemechu et al. - 2024 - ARIES A General Benchmark for Argument Relation Identification.pdf}
}

@inproceedings{hautli-janiszQT30CorpusArgument2022,
  title = {{{QT30}}: {{A Corpus}} of {{Argument}} and {{Conflict}} in {{Broadcast Debate}}},
  shorttitle = {{{QT30}}},
  booktitle = {Proceedings of the {{Thirteenth Language Resources}} and {{Evaluation Conference}}},
  author = {{Hautli-Janisz}, Annette and Kikteva, Zlata and Siskou, Wassiliki and Gorska, Kamila and Becker, Ray and Reed, Chris},
  editor = {Calzolari, Nicoletta and B{\'e}chet, Fr{\'e}d{\'e}ric and Blache, Philippe and Choukri, Khalid and Cieri, Christopher and Declerck, Thierry and Goggi, Sara and Isahara, Hitoshi and Maegaard, Bente and Mariani, Joseph and Mazo, H{\'e}l{\`e}ne and Odijk, Jan and Piperidis, Stelios},
  year = {2022},
  month = jun,
  pages = {3291--3300},
  publisher = {European Language Resources Association},
  address = {Marseille, France},
  urldate = {2024-10-21},
  abstract = {Broadcast political debate is a core pillar of democracy: it is the public's easiest access to opinions that shape policies and enables the general public to make informed choices. With QT30, we present the largest corpus of analysed dialogical argumentation ever created (19,842 utterances, 280,000 words) and also the largest corpus of analysed broadcast political debate to date, using 30 episodes of BBC's `Question Time' from 2020 and 2021. Question Time is the prime institution in UK broadcast political debate and features questions from the public on current political issues, which are responded to by a weekly panel of five figures of UK politics and society. QT30 is highly argumentative and combines language of well-versed political rhetoric with direct, often combative, justification-seeking of the general public. QT30 is annotated with Inference Anchoring Theory, a framework well-known in argument mining, which encodes the way arguments and conflicts are created and reacted to in dialogical settings. The resource is freely available at http://corpora.aifdb.org/qt30.},
  file = {C:\Users\twoca\Zotero\storage\HGPYQRJR\Hautli-Janisz et al. - 2022 - QT30 A Corpus of Argument and Conflict in Broadcast Debate.pdf}
}

@misc{hsuHuBERTSelfSupervisedSpeech2021,
  title = {{{HuBERT}}: {{Self-Supervised Speech Representation Learning}} by {{Masked Prediction}} of {{Hidden Units}}},
  shorttitle = {{{HuBERT}}},
  author = {Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  year = {2021},
  month = jun,
  number = {arXiv:2106.07447},
  eprint = {2106.07447},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2106.07447},
  urldate = {2025-01-29},
  abstract = {Self-supervised approaches for speech representation learning are challenged by three unique problems: (1) there are multiple sound units in each input utterance, (2) there is no lexicon of input sound units during the pre-training phase, and (3) sound units have variable lengths with no explicit segmentation. To deal with these three problems, we propose the Hidden-Unit BERT (HuBERT) approach for self-supervised speech representation learning, which utilizes an offline clustering step to provide aligned target labels for a BERT-like prediction loss. A key ingredient of our approach is applying the prediction loss over the masked regions only, which forces the model to learn a combined acoustic and language model over the continuous inputs. HuBERT relies primarily on the consistency of the unsupervised clustering step rather than the intrinsic quality of the assigned cluster labels. Starting with a simple k-means teacher of 100 clusters, and using two iterations of clustering, the HuBERT model either matches or improves upon the state-of-the-art wav2vec 2.0 performance on the Librispeech (960h) and Libri-light (60,000h) benchmarks with 10min, 1h, 10h, 100h, and 960h fine-tuning subsets. Using a 1B parameter model, HuBERT shows up to 19\% and 13\% relative WER reduction on the more challenging dev-other and test-other evaluation subsets.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {C\:\\Users\\twoca\\Zotero\\storage\\UGXLMT8R\\Hsu et al. - 2021 - HuBERT Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units.pdf;C\:\\Users\\twoca\\Zotero\\storage\\SH72VBZL\\2106.html}
}

@article{lawrenceArgumentMiningSurvey2020,
  title = {Argument {{Mining}}: {{A Survey}}},
  shorttitle = {Argument {{Mining}}},
  author = {Lawrence, John and Reed, Chris},
  year = {2020},
  month = jan,
  journal = {Computational Linguistics},
  volume = {45},
  number = {4},
  pages = {765--818},
  issn = {0891-2017},
  doi = {10.1162/coli_a_00364},
  urldate = {2024-10-08},
  abstract = {Argument mining is the automatic identification and extraction of the structure of inference and reasoning expressed as arguments presented in natural language. Understanding argumentative structure makes it possible to determine not only what positions people are adopting, but also why they hold the opinions they do, providing valuable insights in domains as diverse as financial market prediction and public relations. This survey explores the techniques that establish the foundations for argument mining, provides a review of recent advances in argument mining techniques, and discusses the challenges faced in automatically extracting a deeper understanding of reasoning expressed in language in general.},
  file = {C\:\\Users\\twoca\\Zotero\\storage\\QGF95NS3\\Lawrence and Reed - 2020 - Argument Mining A Survey.pdf;C\:\\Users\\twoca\\Zotero\\storage\\NQ2J6392\\Argument-Mining-A-Survey.html}
}

@misc{liuRoBERTaRobustlyOptimized2019a,
  title = {{{RoBERTa}}: {{A Robustly Optimized BERT Pretraining Approach}}},
  shorttitle = {{{RoBERTa}}},
  author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  year = {2019},
  month = jul,
  number = {arXiv:1907.11692},
  eprint = {1907.11692},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1907.11692},
  urldate = {2025-01-13},
  abstract = {Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\twoca\\Zotero\\storage\\3ZJ95HYU\\Liu et al. - 2019 - RoBERTa A Robustly Optimized BERT Pretraining Approach.pdf;C\:\\Users\\twoca\\Zotero\\storage\\GECP5ZP7\\1907.html}
}

@inproceedings{manciniMAMKitComprehensiveMultimodal2024,
  title = {{{MAMKit}}: {{A Comprehensive Multimodal Argument Mining Toolkit}}},
  shorttitle = {{{MAMKit}}},
  booktitle = {Proceedings of the 11th {{Workshop}} on {{Argument Mining}} ({{ArgMining}} 2024)},
  author = {Mancini, Eleonora and Ruggeri, Federico and Colamonaco, Stefano and Zecca, Andrea and Marro, Samuele and Torroni, Paolo},
  editor = {Ajjour, Yamen and {Bar-Haim}, Roy and El Baff, Roxanne and Liu, Zhexiong and Skitalinskaya, Gabriella},
  year = {2024},
  month = aug,
  pages = {69--82},
  publisher = {Association for Computational Linguistics},
  address = {Bangkok, Thailand},
  doi = {10.18653/v1/2024.argmining-1.7},
  urldate = {2024-10-14},
  abstract = {Multimodal Argument Mining (MAM) is a recent area of research aiming to extend argument analysis and improve discourse understanding by incorporating multiple modalities. Initial results confirm the importance of paralinguistic cues in this field. However, the research community still lacks a comprehensive platform where results can be easily reproduced, and methods and models can be stored, compared, and tested against a variety of benchmarks. To address these challenges, we propose MAMKit, an open, publicly available, PyTorch toolkit that consolidates datasets and models, providing a standardized platform for experimentation. MAMKit also includes some new baselines, designed to stimulate research on text and audio encoding and fusion for MAM tasks. Our initial results with MAMKit indicate that advancements in MAM require novel annotation processes to encompass auditory cues effectively.},
  file = {C:\Users\twoca\Zotero\storage\BUVVFAUI\Mancini et al. - 2024 - MAMKit A Comprehensive Multimodal Argument Mining Toolkit.pdf}
}

@inproceedings{manciniMultimodalArgumentMining2022,
  title = {Multimodal {{Argument Mining}}: {{A Case Study}} in {{Political Debates}}},
  shorttitle = {Multimodal {{Argument Mining}}},
  booktitle = {Proceedings of the 9th {{Workshop}} on {{Argument Mining}}},
  author = {Mancini, Eleonora and Ruggeri, Federico and Galassi, Andrea and Torroni, Paolo},
  editor = {Lapesa, Gabriella and Schneider, Jodi and Jo, Yohan and Saha, Sougata},
  year = {2022},
  month = oct,
  pages = {158--170},
  publisher = {International Conference on Computational Linguistics},
  address = {Online and in Gyeongju, Republic of Korea},
  urldate = {2024-10-16},
  abstract = {We propose a study on multimodal argument mining in the domain of political debates. We collate and extend existing corpora and provide an initial empirical study on multimodal architectures, with a special emphasis on input encoding methods. Our results provide interesting indications about future directions in this important domain.},
  file = {C:\Users\twoca\Zotero\storage\KF8LP66B\Mancini et al. - 2022 - Multimodal Argument Mining A Case Study in Political Debates.pdf}
}

@inproceedings{mestreMArgMultimodalArgument2021,
  title = {M-{{Arg}}: {{Multimodal Argument Mining Dataset}} for {{Political Debates}} with {{Audio}} and {{Transcripts}}},
  shorttitle = {M-{{Arg}}},
  booktitle = {Proceedings of the 8th {{Workshop}} on {{Argument Mining}}},
  author = {Mestre, Rafael and Milicin, Razvan and Middleton, Stuart E. and Ryan, Matt and Zhu, Jiatong and Norman, Timothy J.},
  editor = {{Al-Khatib}, Khalid and Hou, Yufang and Stede, Manfred},
  year = {2021},
  month = nov,
  pages = {78--88},
  publisher = {Association for Computational Linguistics},
  address = {Punta Cana, Dominican Republic},
  doi = {10.18653/v1/2021.argmining-1.8},
  urldate = {2024-10-16},
  abstract = {Argumentation mining aims at extracting, analysing and modelling people's arguments, but large, high-quality annotated datasets are limited, and no multimodal datasets exist for this task. In this paper, we present M-Arg, a multimodal argument mining dataset with a corpus of US 2020 presidential debates, annotated through crowd-sourced annotations. This dataset allows models to be trained to extract arguments from natural dialogue such as debates using information like the intonation and rhythm of the speaker. Our dataset contains 7 hours of annotated US presidential debates, 6527 utterances and 4104 relation labels, and we report results from different baseline models, namely a text-only model, an audio-only model and multimodal models that extract features from both text and audio. With accuracy reaching 0.86 in multimodal models, we find that audio features provide added value with respect to text-only models.},
  file = {C:\Users\twoca\Zotero\storage\LUT49QVY\Mestre et al. - 2021 - M-Arg Multimodal Argument Mining Dataset for Political Debates with Audio and Transcripts.pdf}
}

@article{morioEndtoendArgumentMining2022,
  title = {End-to-End {{Argument Mining}} with {{Cross-corpora Multi-task Learning}}},
  author = {Morio, Gaku and Ozaki, Hiroaki and Morishita, Terufumi and Yanai, Kohsuke},
  year = {2022},
  month = may,
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {10},
  pages = {639--658},
  issn = {2307-387X},
  doi = {10.1162/tacl_a_00481},
  urldate = {2024-10-17},
  abstract = {Mining an argument structure from text is an important step for tasks such as argument search and summarization. While studies on argument(ation) mining have proposed promising neural network models, they usually suffer from a shortage of training data. To address this issue, we expand the training data with various auxiliary argument mining corpora and propose an end-to-end cross-corpus training method called Multi-Task Argument Mining (MT-AM). To evaluate our approach, we conducted experiments for the main argument mining tasks on several well-established argument mining corpora. The results demonstrate that MT-AM generally outperformed the models trained on a single corpus. Also, the smaller the target corpus was, the better the MT-AM performed. Our extensive analyses suggest that the improvement of MT-AM depends on several factors of transferability among auxiliary and target corpora.},
  file = {C:\Users\twoca\Zotero\storage\GCWRJR8F\Morio et al. - 2022 - End-to-end Argument Mining with Cross-corpora Multi-task Learning.pdf}
}

@misc{reedQuickStartGuide2017,
  title = {A {{Quick Start Guide}} to {{Inference Anchoring Theory}} ({{IAT}})},
  author = {Reed, Chris},
  year = {2017},
  month = sep,
  file = {C:\Users\twoca\Zotero\storage\C2X7J2VM\IAT-guidelines.pdf}
}

@inproceedings{ruiz-dolzLookingUnseenEffective2025,
  title = {Looking at the {{Unseen}}: {{Effective Sampling}} of {{Non-Related Propositions}} for {{Argument Mining}}},
  shorttitle = {Looking at the {{Unseen}}},
  booktitle = {Proceedings of the 31st {{International Conference}} on {{Computational Linguistics}}},
  author = {{Ruiz-Dolz}, Ramon and Gemechu, Debela and Kikteva, Zlata and Reed, Chris},
  editor = {Rambow, Owen and Wanner, Leo and Apidianaki, Marianna and {Al-Khalifa}, Hend and Eugenio, Barbara Di and Schockaert, Steven},
  year = {2025},
  month = jan,
  pages = {2131--2143},
  publisher = {Association for Computational Linguistics},
  address = {Abu Dhabi, UAE},
  urldate = {2025-01-27},
  abstract = {Traditionally, argument mining research has approached the task of automatic identification of argument structures by using existing definitions of what constitutes an argument, while leaving the equally important matter of what does not qualify as an argument unaddressed. With the ability to distinguish between what is and what is not a natural language argument being at the core of argument mining as a field, it is interesting that no previous work has explored approaches to effectively select non-related propositions (i.e., propositions that are not connected through an argumentative relation, such as support or attack) that improve the data for learning argument mining tasks better. In this paper, we address the question of how to effectively sample non-related propositions from six different argument mining corpora belonging to different domains and encompassing both monologue and dialogue forms of argumentation. To that end, in addition to considering undersampling baselines from previous work, we propose three new sampling strategies relying on context (i.e., short/long) and the semantic similarity between propositions. Our results indicate that using more informed sampling strategies improves the performance, not only when evaluating models on their respective test splits, but also in the case of cross-domain evaluation.},
  file = {C:\Users\twoca\Zotero\storage\5GVHEBLW\Ruiz-Dolz et al. - 2025 - Looking at the Unseen Effective Sampling of Non-Related Propositions for Argument Mining.pdf}
}

@article{ruiz-dolzTransformerBasedModelsAutomatic2021,
  title = {Transformer-{{Based Models}} for {{Automatic Identification}} of {{Argument Relations}}: {{A Cross-Domain Evaluation}}},
  shorttitle = {Transformer-{{Based Models}} for {{Automatic Identification}} of {{Argument Relations}}},
  author = {{Ruiz-Dolz}, Ramon and Alemany, Jose and Barber{\'a}, Stella M. Heras and {Garc{\'i}a-Fornes}, Ana},
  year = {2021},
  month = nov,
  journal = {IEEE Intelligent Systems},
  volume = {36},
  number = {6},
  pages = {62--70},
  issn = {1941-1294},
  doi = {10.1109/MIS.2021.3073993},
  urldate = {2024-10-10},
  abstract = {Argument mining is defined as the task of automatically identifying and extracting argumentative components (e.g., premises, claims, etc.) and detecting the existing relations among them (i.e., support, attack, rephrase, no relation). One of the main issues when approaching this problem is the lack of data, and the size of the publicly available corpora. In this work, we use the recently annotated US2016 debate corpus. US2016 is the largest existing argument annotated corpus, which allows exploring the benefits of the most recent advances in natural language processing in a complex domain like argument (relation) mining. We present an exhaustive analysis of the behavior of transformer-based models (i.e., BERT, XLNET, RoBERTa, DistilBERT, and ALBERT) when predicting argument relations. Finally, we evaluate the models in five different domains, with the objective of finding the less domain-dependent model. We obtain a macro F1-score of 0.70 with the US2016 evaluation corpus, and a macro F1-score of 0.61 with the Moral Maze cross-domain corpus.},
  keywords = {Computational modeling,Data mining,Ethics,Intelligent systems,Natural language processing,Transformers},
  file = {C:\Users\twoca\Zotero\storage\ZX7CXEJF\Ruiz-Dolz et al. - 2021 - Transformer-Based Models for Automatic Identification of Argument Relations A Cross-Domain Evaluati.pdf}
}

@inproceedings{ruiz-dolzVivesDebateSpeechCorpusSpoken2023,
  title = {{{VivesDebate-Speech}}: {{A Corpus}} of {{Spoken Argumentation}} to {{Leverage Audio Features}} for {{Argument Mining}}},
  shorttitle = {{{VivesDebate-Speech}}},
  booktitle = {Proceedings of the 2023 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {{Ruiz-Dolz}, Ramon and {Iranzo-S{\'a}nchez}, Javier},
  editor = {Bouamor, Houda and Pino, Juan and Bali, Kalika},
  year = {2023},
  month = dec,
  pages = {2071--2077},
  publisher = {Association for Computational Linguistics},
  address = {Singapore},
  doi = {10.18653/v1/2023.emnlp-main.128},
  urldate = {2024-10-14},
  abstract = {In this paper, we describe VivesDebate-Speech, a corpus of spoken argumentation created to leverage audio features for argument mining tasks. The creation of this corpus represents an important contribution to the intersection of speech processing and argument mining communities, and one of the most complete publicly available resources in this topic. Moreover, we have performed a set of first-of-their-kind experiments which show an improvement when integrating audio features into the argument mining pipeline. The provided results can be used as a baseline for future research.},
  file = {C:\Users\twoca\Zotero\storage\VEWQURW8\Ruiz-Dolz and Iranzo-S√°nchez - 2023 - VivesDebate-Speech A Corpus of Spoken Argumentation to Leverage Audio Features for Argument Mining.pdf}
}

@misc{schneiderWav2vecUnsupervisedPretraining2019,
  title = {Wav2vec: {{Unsupervised Pre-training}} for {{Speech Recognition}}},
  shorttitle = {Wav2vec},
  author = {Schneider, Steffen and Baevski, Alexei and Collobert, Ronan and Auli, Michael},
  year = {2019},
  month = sep,
  number = {arXiv:1904.05862},
  eprint = {1904.05862},
  publisher = {arXiv},
  urldate = {2024-10-17},
  abstract = {We explore unsupervised pre-training for speech recognition by learning representations of raw audio. wav2vec is trained on large amounts of unlabeled audio data and the resulting representations are then used to improve acoustic model training. We pre-train a simple multi-layer convolutional neural network optimized via a noise contrastive binary classification task. Our experiments on WSJ reduce WER of a strong character-based log-mel filterbank baseline by up to 36\% when only a few hours of transcribed data is available. Our approach achieves 2.43\% WER on the nov92 test set. This outperforms Deep Speech 2, the best reported character-based system in the literature while using two orders of magnitude less labeled training data.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\twoca\\Zotero\\storage\\ZJL9CLMA\\Schneider et al. - 2019 - wav2vec Unsupervised Pre-training for Speech Recognition.pdf;C\:\\Users\\twoca\\Zotero\\storage\\LRP96J5W\\1904.html}
}

@article{vaswaniAttentionAllYou2017,
  title = {Attention {{Is All You Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\textbackslash}Lukasz and Polosukhin, Illia},
  year = {2017},
  pages = {11},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
  langid = {english},
  keywords = {technology}
}

@inproceedings{wuKnowCompDialAM2024Finetuning2024,
  title = {{{KnowComp}} at {{DialAM-2024}}: {{Fine-tuning Pre-trained Language Models}} for {{Dialogical Argument Mining}} with {{Inference Anchoring Theory}}},
  shorttitle = {{{KnowComp}} at {{DialAM-2024}}},
  booktitle = {Proceedings of the 11th {{Workshop}} on {{Argument Mining}} ({{ArgMining}} 2024)},
  author = {Wu, Yuetong and Zhou, Yukai and Xu, Baixuan and Wang, Weiqi and Song, Yangqiu},
  editor = {Ajjour, Yamen and {Bar-Haim}, Roy and El Baff, Roxanne and Liu, Zhexiong and Skitalinskaya, Gabriella},
  year = {2024},
  month = aug,
  pages = {103--109},
  publisher = {Association for Computational Linguistics},
  address = {Bangkok, Thailand},
  doi = {10.18653/v1/2024.argmining-1.10},
  urldate = {2024-10-17},
  abstract = {In this paper, we present our framework for DialAM-2024 TaskA: Identification of Propositional Relations and TaskB: Identification of Illocutionary Relations. The goal of task A is to detect argumentative relations between propositions in an argumentative dialogue. i.e., Inference, Conflict, Rephrase while task B aims to detect illocutionary relations between locutions and argumentative propositions in a dialogue. e.g., Asserting, Agreeing, Arguing, Disagreeing. Noticing the definition of the relations are strict and professional under the context of IAT framework, we meticulously curate prompts which not only incorporate formal definition of the relations, but also exhibit the subtle differences between them. The PTLMs are then fine-tuned on the human-designed prompts to enhance its discrimination capability in classifying different theoretical relations by learning from the human instruction and the ground truth samples. After extensive experiments, a fine-tuned DeBERTa-v3-base model exhibits the best performance among all PTLMs with an F1 score of 78.90\% on Task B. It is worth noticing that our framework ranks \#2 in the ILO - General official leaderboard.},
  file = {C:\Users\twoca\Zotero\storage\WZX3ABDB\Wu et al. - 2024 - KnowComp at DialAM-2024 Fine-tuning Pre-trained Language Models for Dialogical Argument Mining with.pdf}
}

@inproceedings{zhengKNOWCOMPPOKEMONTeam2024,
  title = {{{KNOWCOMP POKEMON Team}} at {{DialAM-2024}}: {{A Two-Stage Pipeline}} for {{Detecting Relations}} in {{Dialogue Argument Mining}}},
  shorttitle = {{{KNOWCOMP POKEMON Team}} at {{DialAM-2024}}},
  booktitle = {Proceedings of the 11th {{Workshop}} on {{Argument Mining}} ({{ArgMining}} 2024)},
  author = {Zheng, Zihao and Wang, Zhaowei and Zong, Qing and Song, Yangqiu},
  editor = {Ajjour, Yamen and {Bar-Haim}, Roy and El Baff, Roxanne and Liu, Zhexiong and Skitalinskaya, Gabriella},
  year = {2024},
  month = aug,
  pages = {110--118},
  publisher = {Association for Computational Linguistics},
  address = {Bangkok, Thailand},
  doi = {10.18653/v1/2024.argmining-1.11},
  urldate = {2024-10-17},
  abstract = {Dialogue Argument Mining(DialAM) is an important branch of Argument Mining(AM). DialAM-2024 is a shared task focusing on dialogue argument mining, which requires us to identify argumentative relations and illocutionary relations among proposition nodes and locution nodes. To accomplish this, we propose a two-stage pipeline, which includes the Two-Step S-Node Prediction Model in Stage 1 and the YA-Node Prediction Model in Stage 2. We also augment the training data in both stages and introduce context in the prediction of Stage 2. We successfully completed the task and achieved good results. Our team KNOWCOMP POKEMON ranked 1st in the ARI Focused score and 4th in the Global Focused score.},
  file = {C:\Users\twoca\Zotero\storage\XDW4CCLN\Zheng et al. - 2024 - KNOWCOMP POKEMON Team at DialAM-2024 A Two-Stage Pipeline for Detecting Relations in Dialogue Argum.pdf}
}
