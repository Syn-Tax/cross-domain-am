@misc{baevskiWav2vec20Framework2020,
  title = {Wav2vec 2.0: {{A Framework}} for {{Self-Supervised Learning}} of {{Speech Representations}}},
  shorttitle = {Wav2vec 2.0},
  author = {Baevski, Alexei and Zhou, Henry and Mohamed, Abdelrahman and Auli, Michael},
  year = {2020},
  month = oct,
  number = {arXiv:2006.11477},
  eprint = {2006.11477},
  publisher = {arXiv},
  urldate = {2024-10-16},
  abstract = {We show for the first time that learning powerful representations from speech audio alone followed by fine-tuning on transcribed speech can outperform the best semi-supervised methods while being conceptually simpler. wav2vec 2.0 masks the speech input in the latent space and solves a contrastive task defined over a quantization of the latent representations which are jointly learned. Experiments using all labeled data of Librispeech achieve 1.8/3.3 WER on the clean/other test sets. When lowering the amount of labeled data to one hour, wav2vec 2.0 outperforms the previous state of the art on the 100 hour subset while using 100 times less labeled data. Using just ten minutes of labeled data and pre-training on 53k hours of unlabeled data still achieves 4.8/8.2 WER. This demonstrates the feasibility of speech recognition with limited amounts of labeled data.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {C\:\\Users\\twoca\\Zotero\\storage\\Q26TQS78\\Baevski et al. - 2020 - wav2vec 2.0 A Framework for Self-Supervised Learning of Speech Representations.pdf;C\:\\Users\\twoca\\Zotero\\storage\\7C72PL3J\\2006.html}
}

@misc{devlinBERTPretrainingDeep2019b,
  title = {{{BERT}}: {{Pre-training}} of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  shorttitle = {{{BERT}}},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  year = {2019},
  month = may,
  number = {arXiv:1810.04805},
  eprint = {1810.04805},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1810.04805},
  urldate = {2025-01-13},
  abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\twoca\\Zotero\\storage\\AN5I3PLY\\Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf;C\:\\Users\\twoca\\Zotero\\storage\\M9JU6UCV\\1810.html}
}

@inproceedings{duthieCASSTechniqueEvaluating2016,
  title = {The {{CASS Technique}} for {{Evaluating}} the {{Performance}} of {{Argument Mining}}},
  booktitle = {Proceedings of the {{Third Workshop}} on {{Argument Mining}} ({{ArgMining2016}})},
  author = {Duthie, Rory and Lawrence, John and Budzynska, Katarzyna and Reed, Chris},
  editor = {Reed, Chris},
  year = {2016},
  month = aug,
  pages = {40--49},
  publisher = {Association for Computational Linguistics},
  address = {Berlin, Germany},
  doi = {10.18653/v1/W16-2805},
  urldate = {2024-10-24},
  file = {C:\Users\twoca\Zotero\storage\75JZYJCI\Duthie et al. - 2016 - The CASS Technique for Evaluating the Performance of Argument Mining.pdf}
}

@inproceedings{gemechuARIESGeneralBenchmark2024,
  title = {{{ARIES}}: {{A General Benchmark}} for {{Argument Relation Identification}}},
  shorttitle = {{{ARIES}}},
  booktitle = {Proceedings of the 11th {{Workshop}} on {{Argument Mining}} ({{ArgMining}} 2024)},
  author = {Gemechu, Debela and {Ruiz-Dolz}, Ramon and Reed, Chris},
  editor = {Ajjour, Yamen and {Bar-Haim}, Roy and El Baff, Roxanne and Liu, Zhexiong and Skitalinskaya, Gabriella},
  year = {2024},
  month = aug,
  pages = {1--14},
  publisher = {Association for Computational Linguistics},
  address = {Bangkok, Thailand},
  doi = {10.18653/v1/2024.argmining-1.1},
  urldate = {2024-10-14},
  abstract = {Measuring advances in argument mining is one of the main challenges in the area. Different theories of argument, heterogeneous annotations, and a varied set of argumentation domains make it difficult to contextualise and understand the results reported in different work from a general perspective. In this paper, we present ARIES, a general benchmark for Argument Relation Identification aimed at providing with a standard evaluation for argument mining research. ARIES covers the three different language modelling approaches: sequence and token modelling, and sequence-to-sequence-to-sequence alignment, together with the three main Transformer-based model architectures: encoder-only, decoder-only, and encoder-decoder. Furthermore, the benchmark consists of eight different argument mining datasets, covering the most common argumentation domains, and standardised with the same annotation structures. This paper provides a first comprehensive and comparative set of results in argument mining across a broad range of configurations to compare with, both advancing the state-of-the-art, and establishing a standard way to measure future advances in the area. Across varied task setups and architectures, our experiments reveal consistent challenges in cross-dataset evaluation, with notably poor results. Given the models' struggle to acquire transferable skills, the task remains challenging, opening avenues for future research.},
  file = {C:\Users\twoca\Zotero\storage\XVMPNCHL\Gemechu et al. - 2024 - ARIES A General Benchmark for Argument Relation Identification.pdf}
}

@inproceedings{hautli-janiszQT30CorpusArgument2022,
  title = {{{QT30}}: {{A Corpus}} of {{Argument}} and {{Conflict}} in {{Broadcast Debate}}},
  shorttitle = {{{QT30}}},
  booktitle = {Proceedings of the {{Thirteenth Language Resources}} and {{Evaluation Conference}}},
  author = {{Hautli-Janisz}, Annette and Kikteva, Zlata and Siskou, Wassiliki and Gorska, Kamila and Becker, Ray and Reed, Chris},
  editor = {Calzolari, Nicoletta and B{\'e}chet, Fr{\'e}d{\'e}ric and Blache, Philippe and Choukri, Khalid and Cieri, Christopher and Declerck, Thierry and Goggi, Sara and Isahara, Hitoshi and Maegaard, Bente and Mariani, Joseph and Mazo, H{\'e}l{\`e}ne and Odijk, Jan and Piperidis, Stelios},
  year = {2022},
  month = jun,
  pages = {3291--3300},
  publisher = {European Language Resources Association},
  address = {Marseille, France},
  urldate = {2024-10-21},
  abstract = {Broadcast political debate is a core pillar of democracy: it is the public's easiest access to opinions that shape policies and enables the general public to make informed choices. With QT30, we present the largest corpus of analysed dialogical argumentation ever created (19,842 utterances, 280,000 words) and also the largest corpus of analysed broadcast political debate to date, using 30 episodes of BBC's `Question Time' from 2020 and 2021. Question Time is the prime institution in UK broadcast political debate and features questions from the public on current political issues, which are responded to by a weekly panel of five figures of UK politics and society. QT30 is highly argumentative and combines language of well-versed political rhetoric with direct, often combative, justification-seeking of the general public. QT30 is annotated with Inference Anchoring Theory, a framework well-known in argument mining, which encodes the way arguments and conflicts are created and reacted to in dialogical settings. The resource is freely available at http://corpora.aifdb.org/qt30.},
  file = {C:\Users\twoca\Zotero\storage\HGPYQRJR\Hautli-Janisz et al. - 2022 - QT30 A Corpus of Argument and Conflict in Broadcast Debate.pdf}
}

@article{lawrenceArgumentMiningSurvey2020,
  title = {Argument {{Mining}}: {{A Survey}}},
  shorttitle = {Argument {{Mining}}},
  author = {Lawrence, John and Reed, Chris},
  year = {2020},
  month = jan,
  journal = {Computational Linguistics},
  volume = {45},
  number = {4},
  pages = {765--818},
  issn = {0891-2017},
  doi = {10.1162/coli_a_00364},
  urldate = {2024-10-08},
  abstract = {Argument mining is the automatic identification and extraction of the structure of inference and reasoning expressed as arguments presented in natural language. Understanding argumentative structure makes it possible to determine not only what positions people are adopting, but also why they hold the opinions they do, providing valuable insights in domains as diverse as financial market prediction and public relations. This survey explores the techniques that establish the foundations for argument mining, provides a review of recent advances in argument mining techniques, and discusses the challenges faced in automatically extracting a deeper understanding of reasoning expressed in language in general.},
  file = {C\:\\Users\\twoca\\Zotero\\storage\\QGF95NS3\\Lawrence and Reed - 2020 - Argument Mining A Survey.pdf;C\:\\Users\\twoca\\Zotero\\storage\\NQ2J6392\\Argument-Mining-A-Survey.html}
}

@misc{liuRoBERTaRobustlyOptimized2019a,
  title = {{{RoBERTa}}: {{A Robustly Optimized BERT Pretraining Approach}}},
  shorttitle = {{{RoBERTa}}},
  author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  year = {2019},
  month = jul,
  number = {arXiv:1907.11692},
  eprint = {1907.11692},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1907.11692},
  urldate = {2025-01-13},
  abstract = {Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\twoca\\Zotero\\storage\\3ZJ95HYU\\Liu et al. - 2019 - RoBERTa A Robustly Optimized BERT Pretraining Approach.pdf;C\:\\Users\\twoca\\Zotero\\storage\\GECP5ZP7\\1907.html}
}

@inproceedings{manciniMAMKitComprehensiveMultimodal2024,
  title = {{{MAMKit}}: {{A Comprehensive Multimodal Argument Mining Toolkit}}},
  shorttitle = {{{MAMKit}}},
  booktitle = {Proceedings of the 11th {{Workshop}} on {{Argument Mining}} ({{ArgMining}} 2024)},
  author = {Mancini, Eleonora and Ruggeri, Federico and Colamonaco, Stefano and Zecca, Andrea and Marro, Samuele and Torroni, Paolo},
  editor = {Ajjour, Yamen and {Bar-Haim}, Roy and El Baff, Roxanne and Liu, Zhexiong and Skitalinskaya, Gabriella},
  year = {2024},
  month = aug,
  pages = {69--82},
  publisher = {Association for Computational Linguistics},
  address = {Bangkok, Thailand},
  doi = {10.18653/v1/2024.argmining-1.7},
  urldate = {2024-10-14},
  abstract = {Multimodal Argument Mining (MAM) is a recent area of research aiming to extend argument analysis and improve discourse understanding by incorporating multiple modalities. Initial results confirm the importance of paralinguistic cues in this field. However, the research community still lacks a comprehensive platform where results can be easily reproduced, and methods and models can be stored, compared, and tested against a variety of benchmarks. To address these challenges, we propose MAMKit, an open, publicly available, PyTorch toolkit that consolidates datasets and models, providing a standardized platform for experimentation. MAMKit also includes some new baselines, designed to stimulate research on text and audio encoding and fusion for MAM tasks. Our initial results with MAMKit indicate that advancements in MAM require novel annotation processes to encompass auditory cues effectively.},
  file = {C:\Users\twoca\Zotero\storage\BUVVFAUI\Mancini et al. - 2024 - MAMKit A Comprehensive Multimodal Argument Mining Toolkit.pdf}
}

@inproceedings{manciniMultimodalArgumentMining2022,
  title = {Multimodal {{Argument Mining}}: {{A Case Study}} in {{Political Debates}}},
  shorttitle = {Multimodal {{Argument Mining}}},
  booktitle = {Proceedings of the 9th {{Workshop}} on {{Argument Mining}}},
  author = {Mancini, Eleonora and Ruggeri, Federico and Galassi, Andrea and Torroni, Paolo},
  editor = {Lapesa, Gabriella and Schneider, Jodi and Jo, Yohan and Saha, Sougata},
  year = {2022},
  month = oct,
  pages = {158--170},
  publisher = {International Conference on Computational Linguistics},
  address = {Online and in Gyeongju, Republic of Korea},
  urldate = {2024-10-16},
  abstract = {We propose a study on multimodal argument mining in the domain of political debates. We collate and extend existing corpora and provide an initial empirical study on multimodal architectures, with a special emphasis on input encoding methods. Our results provide interesting indications about future directions in this important domain.},
  file = {C:\Users\twoca\Zotero\storage\KF8LP66B\Mancini et al. - 2022 - Multimodal Argument Mining A Case Study in Political Debates.pdf}
}

@inproceedings{mestreMArgMultimodalArgument2021,
  title = {M-{{Arg}}: {{Multimodal Argument Mining Dataset}} for {{Political Debates}} with {{Audio}} and {{Transcripts}}},
  shorttitle = {M-{{Arg}}},
  booktitle = {Proceedings of the 8th {{Workshop}} on {{Argument Mining}}},
  author = {Mestre, Rafael and Milicin, Razvan and Middleton, Stuart E. and Ryan, Matt and Zhu, Jiatong and Norman, Timothy J.},
  editor = {{Al-Khatib}, Khalid and Hou, Yufang and Stede, Manfred},
  year = {2021},
  month = nov,
  pages = {78--88},
  publisher = {Association for Computational Linguistics},
  address = {Punta Cana, Dominican Republic},
  doi = {10.18653/v1/2021.argmining-1.8},
  urldate = {2024-10-16},
  abstract = {Argumentation mining aims at extracting, analysing and modelling people's arguments, but large, high-quality annotated datasets are limited, and no multimodal datasets exist for this task. In this paper, we present M-Arg, a multimodal argument mining dataset with a corpus of US 2020 presidential debates, annotated through crowd-sourced annotations. This dataset allows models to be trained to extract arguments from natural dialogue such as debates using information like the intonation and rhythm of the speaker. Our dataset contains 7 hours of annotated US presidential debates, 6527 utterances and 4104 relation labels, and we report results from different baseline models, namely a text-only model, an audio-only model and multimodal models that extract features from both text and audio. With accuracy reaching 0.86 in multimodal models, we find that audio features provide added value with respect to text-only models.},
  file = {C:\Users\twoca\Zotero\storage\LUT49QVY\Mestre et al. - 2021 - M-Arg Multimodal Argument Mining Dataset for Political Debates with Audio and Transcripts.pdf}
}

@article{morioEndtoendArgumentMining2022,
  title = {End-to-End {{Argument Mining}} with {{Cross-corpora Multi-task Learning}}},
  author = {Morio, Gaku and Ozaki, Hiroaki and Morishita, Terufumi and Yanai, Kohsuke},
  year = {2022},
  month = may,
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {10},
  pages = {639--658},
  issn = {2307-387X},
  doi = {10.1162/tacl_a_00481},
  urldate = {2024-10-17},
  abstract = {Mining an argument structure from text is an important step for tasks such as argument search and summarization. While studies on argument(ation) mining have proposed promising neural network models, they usually suffer from a shortage of training data. To address this issue, we expand the training data with various auxiliary argument mining corpora and propose an end-to-end cross-corpus training method called Multi-Task Argument Mining (MT-AM). To evaluate our approach, we conducted experiments for the main argument mining tasks on several well-established argument mining corpora. The results demonstrate that MT-AM generally outperformed the models trained on a single corpus. Also, the smaller the target corpus was, the better the MT-AM performed. Our extensive analyses suggest that the improvement of MT-AM depends on several factors of transferability among auxiliary and target corpora.},
  file = {C:\Users\twoca\Zotero\storage\GCWRJR8F\Morio et al. - 2022 - End-to-end Argument Mining with Cross-corpora Multi-task Learning.pdf}
}

@misc{reedQuickStartGuide2017,
  title = {A {{Quick Start Guide}} to {{Inference Anchoring Theory}} ({{IAT}})},
  author = {Reed, Chris},
  year = {2017},
  month = sep,
  file = {C:\Users\twoca\Zotero\storage\C2X7J2VM\IAT-guidelines.pdf}
}

@article{ruiz-dolzTransformerBasedModelsAutomatic2021,
  title = {Transformer-{{Based Models}} for {{Automatic Identification}} of {{Argument Relations}}: {{A Cross-Domain Evaluation}}},
  shorttitle = {Transformer-{{Based Models}} for {{Automatic Identification}} of {{Argument Relations}}},
  author = {{Ruiz-Dolz}, Ramon and Alemany, Jose and Barber{\'a}, Stella M. Heras and {Garc{\'i}a-Fornes}, Ana},
  year = {2021},
  month = nov,
  journal = {IEEE Intelligent Systems},
  volume = {36},
  number = {6},
  pages = {62--70},
  issn = {1941-1294},
  doi = {10.1109/MIS.2021.3073993},
  urldate = {2024-10-10},
  abstract = {Argument mining is defined as the task of automatically identifying and extracting argumentative components (e.g., premises, claims, etc.) and detecting the existing relations among them (i.e., support, attack, rephrase, no relation). One of the main issues when approaching this problem is the lack of data, and the size of the publicly available corpora. In this work, we use the recently annotated US2016 debate corpus. US2016 is the largest existing argument annotated corpus, which allows exploring the benefits of the most recent advances in natural language processing in a complex domain like argument (relation) mining. We present an exhaustive analysis of the behavior of transformer-based models (i.e., BERT, XLNET, RoBERTa, DistilBERT, and ALBERT) when predicting argument relations. Finally, we evaluate the models in five different domains, with the objective of finding the less domain-dependent model. We obtain a macro F1-score of 0.70 with the US2016 evaluation corpus, and a macro F1-score of 0.61 with the Moral Maze cross-domain corpus.},
  keywords = {Computational modeling,Data mining,Ethics,Intelligent systems,Natural language processing,Transformers},
  file = {C:\Users\twoca\Zotero\storage\ZX7CXEJF\Ruiz-Dolz et al. - 2021 - Transformer-Based Models for Automatic Identification of Argument Relations A Cross-Domain Evaluati.pdf}
}

@inproceedings{ruiz-dolzVivesDebateSpeechCorpusSpoken2023,
  title = {{{VivesDebate-Speech}}: {{A Corpus}} of {{Spoken Argumentation}} to {{Leverage Audio Features}} for {{Argument Mining}}},
  shorttitle = {{{VivesDebate-Speech}}},
  booktitle = {Proceedings of the 2023 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {{Ruiz-Dolz}, Ramon and {Iranzo-S{\'a}nchez}, Javier},
  editor = {Bouamor, Houda and Pino, Juan and Bali, Kalika},
  year = {2023},
  month = dec,
  pages = {2071--2077},
  publisher = {Association for Computational Linguistics},
  address = {Singapore},
  doi = {10.18653/v1/2023.emnlp-main.128},
  urldate = {2024-10-14},
  abstract = {In this paper, we describe VivesDebate-Speech, a corpus of spoken argumentation created to leverage audio features for argument mining tasks. The creation of this corpus represents an important contribution to the intersection of speech processing and argument mining communities, and one of the most complete publicly available resources in this topic. Moreover, we have performed a set of first-of-their-kind experiments which show an improvement when integrating audio features into the argument mining pipeline. The provided results can be used as a baseline for future research.},
  file = {C:\Users\twoca\Zotero\storage\VEWQURW8\Ruiz-Dolz and Iranzo-Sánchez - 2023 - VivesDebate-Speech A Corpus of Spoken Argumentation to Leverage Audio Features for Argument Mining.pdf}
}

@misc{schneiderWav2vecUnsupervisedPretraining2019,
  title = {Wav2vec: {{Unsupervised Pre-training}} for {{Speech Recognition}}},
  shorttitle = {Wav2vec},
  author = {Schneider, Steffen and Baevski, Alexei and Collobert, Ronan and Auli, Michael},
  year = {2019},
  month = sep,
  number = {arXiv:1904.05862},
  eprint = {1904.05862},
  publisher = {arXiv},
  urldate = {2024-10-17},
  abstract = {We explore unsupervised pre-training for speech recognition by learning representations of raw audio. wav2vec is trained on large amounts of unlabeled audio data and the resulting representations are then used to improve acoustic model training. We pre-train a simple multi-layer convolutional neural network optimized via a noise contrastive binary classification task. Our experiments on WSJ reduce WER of a strong character-based log-mel filterbank baseline by up to 36\% when only a few hours of transcribed data is available. Our approach achieves 2.43\% WER on the nov92 test set. This outperforms Deep Speech 2, the best reported character-based system in the literature while using two orders of magnitude less labeled training data.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\twoca\\Zotero\\storage\\ZJL9CLMA\\Schneider et al. - 2019 - wav2vec Unsupervised Pre-training for Speech Recognition.pdf;C\:\\Users\\twoca\\Zotero\\storage\\LRP96J5W\\1904.html}
}

@inproceedings{wuKnowCompDialAM2024Finetuning2024,
  title = {{{KnowComp}} at {{DialAM-2024}}: {{Fine-tuning Pre-trained Language Models}} for {{Dialogical Argument Mining}} with {{Inference Anchoring Theory}}},
  shorttitle = {{{KnowComp}} at {{DialAM-2024}}},
  booktitle = {Proceedings of the 11th {{Workshop}} on {{Argument Mining}} ({{ArgMining}} 2024)},
  author = {Wu, Yuetong and Zhou, Yukai and Xu, Baixuan and Wang, Weiqi and Song, Yangqiu},
  editor = {Ajjour, Yamen and {Bar-Haim}, Roy and El Baff, Roxanne and Liu, Zhexiong and Skitalinskaya, Gabriella},
  year = {2024},
  month = aug,
  pages = {103--109},
  publisher = {Association for Computational Linguistics},
  address = {Bangkok, Thailand},
  doi = {10.18653/v1/2024.argmining-1.10},
  urldate = {2024-10-17},
  abstract = {In this paper, we present our framework for DialAM-2024 TaskA: Identification of Propositional Relations and TaskB: Identification of Illocutionary Relations. The goal of task A is to detect argumentative relations between propositions in an argumentative dialogue. i.e., Inference, Conflict, Rephrase while task B aims to detect illocutionary relations between locutions and argumentative propositions in a dialogue. e.g., Asserting, Agreeing, Arguing, Disagreeing. Noticing the definition of the relations are strict and professional under the context of IAT framework, we meticulously curate prompts which not only incorporate formal definition of the relations, but also exhibit the subtle differences between them. The PTLMs are then fine-tuned on the human-designed prompts to enhance its discrimination capability in classifying different theoretical relations by learning from the human instruction and the ground truth samples. After extensive experiments, a fine-tuned DeBERTa-v3-base model exhibits the best performance among all PTLMs with an F1 score of 78.90\% on Task B. It is worth noticing that our framework ranks \#2 in the ILO - General official leaderboard.},
  file = {C:\Users\twoca\Zotero\storage\WZX3ABDB\Wu et al. - 2024 - KnowComp at DialAM-2024 Fine-tuning Pre-trained Language Models for Dialogical Argument Mining with.pdf}
}

@inproceedings{zhengKNOWCOMPPOKEMONTeam2024,
  title = {{{KNOWCOMP POKEMON Team}} at {{DialAM-2024}}: {{A Two-Stage Pipeline}} for {{Detecting Relations}} in {{Dialogue Argument Mining}}},
  shorttitle = {{{KNOWCOMP POKEMON Team}} at {{DialAM-2024}}},
  booktitle = {Proceedings of the 11th {{Workshop}} on {{Argument Mining}} ({{ArgMining}} 2024)},
  author = {Zheng, Zihao and Wang, Zhaowei and Zong, Qing and Song, Yangqiu},
  editor = {Ajjour, Yamen and {Bar-Haim}, Roy and El Baff, Roxanne and Liu, Zhexiong and Skitalinskaya, Gabriella},
  year = {2024},
  month = aug,
  pages = {110--118},
  publisher = {Association for Computational Linguistics},
  address = {Bangkok, Thailand},
  doi = {10.18653/v1/2024.argmining-1.11},
  urldate = {2024-10-17},
  abstract = {Dialogue Argument Mining(DialAM) is an important branch of Argument Mining(AM). DialAM-2024 is a shared task focusing on dialogue argument mining, which requires us to identify argumentative relations and illocutionary relations among proposition nodes and locution nodes. To accomplish this, we propose a two-stage pipeline, which includes the Two-Step S-Node Prediction Model in Stage 1 and the YA-Node Prediction Model in Stage 2. We also augment the training data in both stages and introduce context in the prediction of Stage 2. We successfully completed the task and achieved good results. Our team KNOWCOMP POKEMON ranked 1st in the ARI Focused score and 4th in the Global Focused score.},
  file = {C:\Users\twoca\Zotero\storage\XDW4CCLN\Zheng et al. - 2024 - KNOWCOMP POKEMON Team at DialAM-2024 A Two-Stage Pipeline for Detecting Relations in Dialogue Argum.pdf}
}
